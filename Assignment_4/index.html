<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="/~kstew2/style.css" type="text/css" media="screen" title="no title" charset="utf-8">
<title>Assignment 4: Synchronization</title>
</head>
<body>
<div id=content>
<h1>Assignment 4: Synchronization</h1>

<p><strong>Due Friday, November 20th</strong></p>

<h2>Overview</h2>

<h3>Mutual Exclusion</h3>

<p>Have a look at the following <a href="demo/demo1.c">demo program</a>. Does this program
require explicit synchronization? There's a shared variable, <code>buf</code>, accessed
both by the thread executing <code>read_file</code> and the main thread. However, there is
no danger of any concurrent accesses, since our system is running cooperatively
on a single kernel thread, and neither thread calls <code>yield</code> during its
operation.</p>

<p>Thus <code>buf</code> is implicitly protected by mutual exclusion.  So, what output can we
expect from this program? </p>

<p>Since our implementation of <code>thread_fork</code> causes the child thread to run
immediately, <code>read_file</code> will read random bytes into the buffer, finish, and
<code>yield</code>s back to main, which will then calls <code>zero_buf</code>.  This fills the buffer
with all zeroes.  When the contents of the buffer are printed, it will be all
zeroes.</p>

<p>Now have a look at this <a href="demo/demo2.c">identical version</a>, where the call to
<code>read</code> is replaced with <a href="../assign3"><code>read_wrap</code></a>.</p>

<p>Assuming again that <code>thread_fork</code> causes the child thread to run immediately,
then <code>read_wrap</code> will run first and <code>yield</code> after starting the asynchronous
read.  Then <code>zero_buf</code> will run. <code>zero_buf</code> doesn't yield, so it should run to
completion, and after it completes we should expect that the buffer is filled
with all zeroes.</p>

<p>Next, <code>scheduler_end</code> will run, which will <code>yield</code> back and forth with
<code>read_wrap</code> until its read is complete.  Once the read is complete, the buffer
should be filled with all random bytes. So we should expect the program to print
out a buffer filled with entirely random bytes.</p>

<p>Go ahead and compile and link <code>demo2.c</code> with your scheduler. What do you notice?
Here is an <a href="demo/demo2output">section of output</a> from a sample run of <code>demo2.c</code>.
Contrary to our expectations, the zeroes are overlapped with the random bytes!
Somehow, the execution of both threads became concurrent, and the
data was corrupted as a result.</p>

<p>How did our system achieve concurrency with only a single kernel thread?  Well,
the asynchronous I/O call at the heart of <code>read_wrap</code> requires that work is done
in the background to service the I/O request; this work may be done on the same
CPU by switching out the current kernel thread, or on another CPU. The result is
the same: overlapping accesses to the same buffer.</p>

<p>It's worth noting that this behavior depends on an implementation of <code>read_wrap</code>
that passes <code>buf</code> directly to <code>aio_read</code>. An implementation of <code>read_wrap</code>
that creates a local buffer and then copies into <code>buf</code> after the read is
complete would not have this issue. However, this would
require performing a potentially expensive array copy.</p>

<p>It's better to optimize for the common case, where there are no concurrent
accesses, and pass in <code>buf</code> directly. However, this invalidates our
guarantee that we can achieve mutual exclusion simply by not calling <code>yield</code>
within a critical section. Thus, our system needs some explicit
mechanism for mutual exclusion. In this assignment, we'll add blocking
mutex locks.</p>

<h3>Conditional Waiting</h3>

<p>Another thing missing from our system so far has been a way for threads
to wait until some condition becomes true, such as some quantity of a shared
resource becoming available. Without concurrency, this can be done at the
application level by using shared global variables and busy-waiting, but it
would be more practical to give the user a structured interface, that
incorporates blocking, such as condition variables (see <a href="http://web.cecs.pdx.edu/ ~walpole/class/cs533/fall2015/slides/2.pdf">this slide
set</a> from
the start of the term).</p>

<h2>Design Choices</h2>

<h3>Blocking vs. Busy-waiting (revisited)</h3>

<p>Recall in the <a href="../assign3/#blocking">last assignment</a> that we decided in favor
of busy-waiting instead of blocking while waiting for I/O completion. This is
because I/O completion is an external event whose completion time is unknown,
and a combination of polling and busy-waiting was the simplest solution for our
purposes.</p>

<p>However, a mutex becoming free is <em>not</em> an external event; it is a synchronous
operation that is performed by a thread. Busy-waiting for a mutex to become free
is always wasted work, because there's no chance of progress: the only thing
that can wake up the spinning thread is another user-level thread, 
who will not be making any progress while the spinner is running.</p>

<p>The same issue applies to condition variables. Thus, in this assignment, we'll
create true blocking mutex locks and condition variables.</p>

<h3>Consequences of Blocking</h3>

<p>In the absence of true blocking, all previous versions of our scheduler have
maintained the invariant that there is always at least one runnable thread.
Thus, as long as the current thread enqueues itself on the ready list before
dequeuing a thread, the ready list will never run empty. An empty ready list is
a very undesirable situation, because control flow has nowhere sane to go!</p>

<p>Once we introduce true blocking, we also introduce the possibility that all
threads might become blocked, which could result in the ready list becoming
empty. Consider the case where there is one runnable thread, and it blocks -- it
would not enqueue itself on the ready list, thus there would be nothing to
dequeue (and nothing to switch to). In our implementation, this would cause our 
program to crash.</p>

<p>You might notice, however, that this situation is a fatal error with a precise
cause: since our system does not feature asynchronous software interrupts
(signals), if a thread blocks and there are no other runnable threads, then
there are no events that can come to that thread's "rescue" and cause it to
unblock. This is an unrecoverable deadlock.</p>

<p>If our system did use signals (for instance to deal with I/O completion events
instead of polling), then we would need to introduce an "idle thread". While
there was still work to do, the idle thread would simply call <code>yield</code>. If the
ready list became empty, the idle thread would wait for a signal to arrive
(see <a href="http://linux.die.net/man/2/pause"><code>pause(2)</code></a>).</p>

<h2>Implementation</h2>

<ol>
<li><p>Modify your <code>yield</code> routine to prevent a thread whose status is <code>BLOCKED</code>
from enqueuing itself on the ready list. Since our system does not use
signals, your implementation should reflect the fact that it is a fatal error
to block when the ready list is empty.</p></li>
<li><p>Design and implement mutex lock that provides mutual exclusion between
the lock and unlock primitives by blocking any thread that attempts
to lock a mutex that is currently held. </p>

<p>I suggest the following data structure:</p>

<pre><code>   struct mutex {
     int held;
     struct queue waiting_threads;
   };
</code></pre>

<p>And the following operations:</p>

<ul>
<li><code>void mutex_init(struct mutex *)</code></li>
<li><code>void mutex_lock(struct mutex *)</code></li>
<li><code>void mutex_unlock(struct mutex *)</code></li>
</ul>

<p><code>mutex_init</code> should initialize all fields of <code>struct mutex</code>.
<code>mutex_lock</code> should attempt to acquire the lock, and block the calling
thread if the lock is already held. <code>mutex_unlock</code> should wake
up a thread waiting for the lock by putting it back on the ready list,
or free the lock if no threads are waiting.</p></li>
<li><p>Design and implement a condition variable that has MESA semantics.
I suggest the following data structure:</p>

<pre><code>   struct condition {
     struct queue waiting_threads;
   };
</code></pre>

<p>And the following operations:</p>

<ul>
<li><code>void condition_init(struct condition *)</code></li>
<li><code>void condition_wait(struct condition *, struct mutex *)</code></li>
<li><code>void condition_signal(struct condition *)</code></li>
<li><code>void condition_broadcast(struct condition *)</code></li>
</ul>

<p><code>condition_init</code> should initialize all fields of <code>struct condition</code>.
<code>condition_wait</code> should unlock the supplied mutex and cause the thread
to block. The mutex should be re-locked after the thread wakes up.
<code>condition_signal</code> should wake up a waiting thread by adding it back
on to the ready list. <code>condition_broadcast</code> should
<code>signal</code> all waiting threads.</p></li>
</ol>

<h2>Testing</h2>

<ol>
<li><p><a href="counter_test.c">This test program</a> is designed to verify the semantics
of your mutex lock, namely that a thread holding the lock has exclusive
access to the critical section protected by the lock, and that all blocked
threads eventually wake up and have a chance to run in the critical section.</p>

<p>It creates 5 threads to each increment a shared counter 10 times, calling
<code>yield</code> at a very inopportune time. If your mutex is working correctly, you
will see the values 1 through 50, consecutively numbered. If your mutex does
not work properly, the values printed out will be inconsistent.</p></li>
<li><p>Test your condition variables by implementing <code>thread_join</code> using condition
variables. This will require you to add a mutex and condition variable
to the thread control block.</p>

<p><code>thread_join</code> should have the following prototype:</p>

<pre><code>   void thread_join(struct thread*);
</code></pre>

<p>To allow <code>thread_join</code> to be used in practice, you should modify
<code>thread_fork</code> to return a pointer to the newly created thread's thread
control block.</p>

<p><a href="sort_test.c">This test program</a> will test your implementation of
<code>thread_join</code> with a "parallel" mergesort procedure.   </p></li>
<li><p>Feel free to write any other tests you see fit!</p></li>
</ol>

<h2>Discussion</h2>

<p>Our mutex locks works because the lock variables themselves are implicitly
protected by mutual exclusion -- the <code>lock</code> and <code>unlock</code> operations are "atomic"
because they do not yield and should not be affected by asynchronous reading
operations. </p>

<p>Your next assignment will be to add a second kernel thread to your user-level
thread scheduler, to allow two user-level threads to run in parallel. How
will this affect the operation of your blocking mutex lock? What additional
mechanisms might we need in order to ensure that our programs are safe?</p>

<h2>What To Hand In</h2>

<p>You should submit:</p>

<ol>
<li><p>All scheduler code so far. This should include:</p>

<ul>
<li><code>switch.s</code></li>
<li><code>queue.h</code></li>
<li><code>queue.c</code></li>
<li><code>scheduler.h</code></li>
<li><code>scheduler.c</code></li>
<li><code>async.c</code> </li>
</ul></li>
<li><p>If you modified <code>counter_test.c</code> or <code>sort_test.c</code>, turn in
the modified versions. Also turn in any tests you wrote yourself.</p></li>
<li><p>A brief written report, including:</p>

<ol>
<li>A description of what you did and how you tested it.</li>
<li>Your response to the question in "Discussion", above.</li>
</ol></li>
</ol>

<p>Please submit your code files <em>as-is</em>; do not copy them into a Word 
document or PDF.<br>
Plain text is also preferred for your write-up.<br>
You may wrap your files in an archive such as a .tar file.</p>

<p>Email your submission to the TA at <u>kstew2 at cs.pdx.edu</u> on or before the
due date. The subject line should be "CS533 Assignment 4".</p>

<h2>Need Help?</h2>

<p>If you have any questions or concerns, or want clarification, feel free
to <a href="/kstew2/cs533/">contact the TA</a> by coming to office hours or sending an
email.</p>

<p>You may also send an email to the 
<a href="https://mailhost.cecs.pdx.edu/mailman/listinfo/cs533">class mailing list</a>. Your
peers will see these emails, as will the TA and professor.</p>

</div>
</body>
</html>
